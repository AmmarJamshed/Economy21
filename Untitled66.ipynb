{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9grCnIzsIHdkEM1OB2wNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmmarJamshed/Economy21/blob/main/Untitled66.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xz33xvQSjNs0",
        "outputId": "adc47f3f-d6bd-470a-d941-dd05f0ab8d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table after training:\n",
            "[[ 22.87822878  22.87822878  20.5904059   21.5904059 ]\n",
            " [ 26.53136531  25.5904059   23.87822878 -50.        ]\n",
            " [ 36.53136531  30.5904059   40.5904059  -50.        ]\n",
            " [  0.           0.           0.           0.        ]]\n",
            "Initial State: Safe\n",
            "Action Taken: Slow Down\n",
            "Next State: Pedestrian Detected\n",
            "Action Taken: Slow Down\n",
            "Next State: Near Collision\n",
            "Action Taken: Change Direction\n",
            "Next State: Safe\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the environment\n",
        "states = [\"Safe\", \"Pedestrian Detected\", \"Near Collision\", \"Collision\"]\n",
        "actions = [\"Slow Down\", \"Stop\", \"Change Direction\", \"Move Forward\"]\n",
        "\n",
        "# Initialize Q-table\n",
        "q_table = np.zeros((len(states), len(actions)))\n",
        "\n",
        "# Parameters for Q-Learning\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.9  # Discount factor\n",
        "epsilon = 0.2  # Exploration rate\n",
        "episodes = 1000\n",
        "\n",
        "# State transition simulation\n",
        "def get_next_state(state, action):\n",
        "    if state == \"Safe\" and action == \"Move Forward\":\n",
        "        return \"Safe\", 1\n",
        "    elif state == \"Safe\" and action in [\"Slow Down\", \"Stop\"]:\n",
        "        return \"Pedestrian Detected\", -1\n",
        "    elif state == \"Pedestrian Detected\" and action == \"Stop\":\n",
        "        return \"Safe\", 5\n",
        "    elif state == \"Pedestrian Detected\" and action == \"Slow Down\":\n",
        "        return \"Near Collision\", -10\n",
        "    elif state == \"Near Collision\" and action == \"Stop\":\n",
        "        return \"Safe\", 10\n",
        "    elif state == \"Near Collision\" and action == \"Change Direction\":\n",
        "        return \"Safe\", 20\n",
        "    elif state in [\"Pedestrian Detected\", \"Near Collision\"] and action == \"Move Forward\":\n",
        "        return \"Collision\", -50\n",
        "    return state, 0\n",
        "\n",
        "# Map states to indices for the Q-table\n",
        "state_to_index = {state: i for i, state in enumerate(states)}\n",
        "action_to_index = {action: i for i, action in enumerate(actions)}\n",
        "\n",
        "# Q-Learning algorithm\n",
        "for episode in range(episodes):\n",
        "    state = \"Safe\"  # Start state\n",
        "    for _ in range(50):  # Max steps per episode\n",
        "        state_idx = state_to_index[state]\n",
        "\n",
        "        # Choose action using epsilon-greedy policy\n",
        "        if random.random() < epsilon:\n",
        "            action = random.choice(actions)  # Explore\n",
        "        else:\n",
        "            action = actions[np.argmax(q_table[state_idx])]  # Exploit\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        next_state, reward = get_next_state(state, action)\n",
        "        next_state_idx = state_to_index[next_state]\n",
        "\n",
        "        # Update Q-value\n",
        "        q_table[state_idx, action_to_index[action]] += alpha * (\n",
        "            reward + gamma * np.max(q_table[next_state_idx]) - q_table[state_idx, action_to_index[action]]\n",
        "        )\n",
        "\n",
        "        # Transition to next state\n",
        "        state = next_state\n",
        "\n",
        "        # End episode if collision\n",
        "        if state == \"Collision\":\n",
        "            break\n",
        "\n",
        "# Display learned Q-table\n",
        "print(\"Q-Table after training:\")\n",
        "print(q_table)\n",
        "\n",
        "# Simulate the policy\n",
        "def simulate_policy():\n",
        "    state = \"Safe\"\n",
        "    print(f\"Initial State: {state}\")\n",
        "    while state != \"Collision\":\n",
        "        state_idx = state_to_index[state]\n",
        "        action = actions[np.argmax(q_table[state_idx])]\n",
        "        print(f\"Action Taken: {action}\")\n",
        "        next_state, _ = get_next_state(state, action)\n",
        "        print(f\"Next State: {next_state}\")\n",
        "        if next_state == \"Safe\" or next_state == \"Collision\":\n",
        "            break\n",
        "        state = next_state\n",
        "\n",
        "simulate_policy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ijW-TRFDkHtj"
      }
    }
  ]
}